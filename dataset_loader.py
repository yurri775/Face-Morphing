import kagglehub
import numpy as np
import cv2
import json
from pathlib import Path
from typing import Tuple, List, Optional, Dict, Any
import matplotlib.pyplot as plt

class OlivettiDatasetLoader:
    """Gestionnaire complet pour le dataset Olivetti Faces augment√©"""
    
    def __init__(self, metadata_file: Optional[str] = None, cache_dir: str = "data"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.dataset_path = None
        self.faces = None
        self.labels = None
        self.metadata = None
        
        # Charger les m√©tadonn√©es si disponibles
        if metadata_file and Path(metadata_file).exists():
            self.load_metadata(metadata_file)
    
    def load_metadata(self, metadata_file: str) -> None:
        """Charge les m√©tadonn√©es JSON du dataset"""
        with open(metadata_file, 'r', encoding='utf-8') as f:
            self.metadata = json.load(f)
        print(f"‚úì M√©tadonn√©es charg√©es depuis: {metadata_file}")
    
    def download_dataset(self) -> str:
        """T√©l√©charge le dataset depuis Kaggle avec kagglehub"""
        print("=== T√©l√©chargement du Dataset Olivetti Augment√© ===")
        print("Utilisation de kagglehub pour t√©l√©charger...")
        
        # Code kagglehub int√©gr√©
        path = kagglehub.dataset_download("martininf1n1ty/olivetti-faces-augmented-dataset")
        
        self.dataset_path = Path(path)
        print(f"‚úì Dataset t√©l√©charg√© dans: {path}")
        
        # Afficher les informations du dataset si m√©tadonn√©es disponibles
        if self.metadata:
            self._print_dataset_info()
        
        return path
    
    def _print_dataset_info(self) -> None:
        """Affiche les informations du dataset √† partir des m√©tadonn√©es"""
        if not self.metadata:
            return
            
        print(f"\n=== Informations du Dataset ===")
        print(f"üìä Nom: {self.metadata.get('name', 'N/A')}")
        print(f"üë®‚Äçüíª Cr√©ateur: {self.metadata.get('creator', {}).get('name', 'N/A')}")
        print(f"üìù Version: {self.metadata.get('version', 'N/A')}")
        print(f"üìÖ Date de publication: {self.metadata.get('datePublished', 'N/A')}")
        print(f"üìÑ Licence: {self.metadata.get('license', {}).get('name', 'N/A')}")
        
        # Extraire les d√©tails de la description
        desc = self.metadata.get('description', '')
        if '2000' in desc:
            print(f"üñºÔ∏è  Total d'images: 2000 (400 originales + 1600 augment√©es)")
            print(f"üë• Personnes: 40 (50 images par personne)")
    
    def load_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """Charge les fichiers .npy du dataset"""
        if self.dataset_path is None:
            self.download_dataset()
            
        faces_path = self.dataset_path / "augmented_faces.npy"
        labels_path = self.dataset_path / "augmented_labels.npy"
        
        if not faces_path.exists() or not labels_path.exists():
            raise FileNotFoundError(f"Fichiers non trouv√©s dans: {self.dataset_path}")
        
        print("\n=== Chargement des Donn√©es ===")
        self.faces = np.load(str(faces_path))
        self.labels = np.load(str(labels_path))
        
        # Validation des donn√©es
        self._validate_data()
        
        return self.faces, self.labels
    
    def _validate_data(self) -> None:
        """Valide les donn√©es charg√©es contre les m√©tadonn√©es"""
        print(f"‚úì Images charg√©es: {self.faces.shape}")
        print(f"‚úì Labels charg√©s: {self.labels.shape}")
        print(f"‚úì Type de donn√©es: {self.faces.dtype}")
        print(f"‚úì Plage de valeurs: [{self.faces.min():.3f}, {self.faces.max():.3f}]")
        
        # V√©rifications contre m√©tadonn√©es
        if self.metadata:
            expected_total = 2000
            if len(self.faces) == expected_total:
                print(f"‚úÖ Nombre d'images correct: {expected_total}")
            else:
                print(f"‚ö†Ô∏è  Nombre d'images inattendu: {len(self.faces)} vs {expected_total}")
        
        # Statistiques des personnes
        unique_persons = len(np.unique(self.labels))
        print(f"‚úì Personnes uniques d√©tect√©es: {unique_persons}")
        
        # Images par personne
        person_counts = np.bincount(self.labels)
        print(f"‚úì Images par personne: min={person_counts.min()}, max={person_counts.max()}, moyenne={person_counts.mean():.1f}")
    
    def get_face_by_person(self, person_id: int, max_images: Optional[int] = None) -> np.ndarray:
        """R√©cup√®re les images d'une personne sp√©cifique"""
        if self.faces is None or self.labels is None:
            self.load_data()
            
        mask = self.labels == person_id
        person_faces = self.faces[mask]
        
        if max_images:
            person_faces = person_faces[:max_images]
            
        return person_faces
    
    def get_random_faces(self, count: int = 2) -> List[np.ndarray]:
        """R√©cup√®re des visages al√©atoires"""
        if self.faces is None:
            self.load_data()
            
        indices = np.random.choice(len(self.faces), count, replace=False)
        return [self.faces[i] for i in indices]
    
    def preprocess_for_morphing(self, face: np.ndarray, target_size: Tuple[int, int] = (256, 256)) -> np.ndarray:
        """Pr√©process une image pour le morphing - VERSION CORRIG√âE"""
        # 1. Convertir en float32 pour √©viter les probl√®mes OpenCV avec float64
        face = face.astype(np.float32)
        
        # 2. Normaliser les valeurs dans [0, 1]
        if face.max() > 1.0:
            face = face / 255.0
        
        # 3. S'assurer que les valeurs sont strictement dans [0, 1]
        face = np.clip(face, 0.0, 1.0)
        
        # 4. Redimensionner si n√©cessaire
        if face.shape[:2] != target_size:
            face = cv2.resize(face, target_size, interpolation=cv2.INTER_LINEAR)
            
        # 5. Convertir en RGB sans utiliser cv2.cvtColor (probl√©matique avec float64)
        if len(face.shape) == 2:
            # Pour les images en niveaux de gris, cr√©er 3 canaux identiques
            face = np.stack([face, face, face], axis=-1)
        elif len(face.shape) == 3 and face.shape[2] == 1:
            # Si c'est (H, W, 1), r√©pliquer sur 3 canaux
            face = np.repeat(face, 3, axis=2)
            
        return face
    
    def display_sample_gallery(self, count: int = 12, persons: Optional[List[int]] = None) -> None:
        """Affiche une galerie d'√©chantillons"""
        if self.faces is None:
            self.load_data()
            
        if persons:
            # Afficher des √©chantillons de personnes sp√©cifiques
            faces_to_show = []
            labels_to_show = []
            for person_id in persons[:count]:
                person_faces = self.get_face_by_person(person_id, 1)
                if len(person_faces) > 0:
                    faces_to_show.append(person_faces[0])
                    labels_to_show.append(person_id)
        else:
            # √âchantillons al√©atoires
            indices = np.random.choice(len(self.faces), min(count, len(self.faces)), replace=False)
            faces_to_show = [self.faces[i] for i in indices]
            labels_to_show = [self.labels[i] for i in indices]
        
        # Affichage avec gestion des types de donn√©es
        rows = int(np.ceil(len(faces_to_show) / 4))
        fig, axes = plt.subplots(rows, 4, figsize=(15, 4*rows))
        if rows == 1:
            axes = axes.reshape(1, -1)
            
        for i, (face, label) in enumerate(zip(faces_to_show, labels_to_show)):
            if i < axes.size:
                ax = axes.flat[i]
                
                # Normaliser et convertir pour affichage
                display_face = face.astype(np.float32)
                if display_face.max() > 1.0:
                    display_face = display_face / 255.0
                
                # S'assurer que les valeurs sont dans [0, 1]
                display_face = np.clip(display_face, 0.0, 1.0)
                    
                ax.imshow(display_face, cmap='gray')
                ax.set_title(f"Personne {label}")
                ax.axis('off')
        
        # Cacher les axes inutilis√©s
        for i in range(len(faces_to_show), axes.size):
            axes.flat[i].axis('off')
            
        plt.suptitle("√âchantillons du Dataset Olivetti Augment√©", fontsize=16)
        plt.tight_layout()
        plt.show()
    
    def get_morphing_pair(self, method: str = "different_persons") -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
        """Obtient une paire de visages optimis√©e pour le morphing"""
        if self.faces is None:
            self.load_data()
        
        if method == "different_persons":
            # S√©lectionner deux personnes diff√©rentes
            unique_persons = np.unique(self.labels)
            selected_persons = np.random.choice(unique_persons, 2, replace=False)
            
            face1 = self.get_face_by_person(selected_persons[0], 1)[0]
            face2 = self.get_face_by_person(selected_persons[1], 1)[0]
            
            info = {
                'person1_id': int(selected_persons[0]),
                'person2_id': int(selected_persons[1]),
                'method': method,
                'original_shapes': [face1.shape, face2.shape]
            }
        else:  # random
            faces = self.get_random_faces(2)
            face1, face2 = faces[0], faces[1]
            info = {'method': 'random'}
        
        # Pr√©processer pour le morphing avec la version corrig√©e
        processed_face1 = self.preprocess_for_morphing(face1)
        processed_face2 = self.preprocess_for_morphing(face2)
        
        return processed_face1, processed_face2, info
    
    def export_dataset_info(self, output_file: str = "dataset_info.txt") -> None:
        """Exporte les informations du dataset"""
        output_path = self.cache_dir / output_file
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("=== DATASET OLIVETTI FACES AUGMENT√â ===\n\n")
            
            if self.metadata:
                f.write(f"Nom: {self.metadata.get('name', 'N/A')}\n")
                f.write(f"Cr√©ateur: {self.metadata.get('creator', {}).get('name', 'N/A')}\n")
                f.write(f"Version: {self.metadata.get('version', 'N/A')}\n")
                f.write(f"URL: {self.metadata.get('url', 'N/A')}\n")
                f.write(f"Licence: {self.metadata.get('license', {}).get('name', 'N/A')}\n\n")
            
            if self.faces is not None:
                f.write("=== STATISTIQUES ===\n")
                f.write(f"Total d'images: {len(self.faces)}\n")
                f.write(f"Forme des images: {self.faces.shape[1:]}\n")
                f.write(f"Type de donn√©es: {self.faces.dtype}\n")
                f.write(f"Personnes uniques: {len(np.unique(self.labels))}\n")
                f.write(f"Plage de valeurs: [{self.faces.min():.3f}, {self.faces.max():.3f}]\n")
        
        print(f"üìÑ Informations export√©es vers: {output_path}")
